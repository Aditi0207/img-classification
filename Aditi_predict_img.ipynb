{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "from tflearn.data_utils import shuffle\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "from tflearn.data_utils import image_preloader\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet_ = input_data(shape=[None, 32, 32, 3])\n",
    "def convn():\n",
    "    convnet = conv_2d(convnet_, 32, 3, activation='relu')\n",
    "\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "    convnet = conv_2d(convnet, 64, 3, activation='relu')\n",
    "\n",
    "    convnet = conv_2d(convnet, 64, 3, activation='relu')\n",
    "\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "    convnet = fully_connected(convnet, 512, activation='relu')\n",
    "\n",
    "    convnet = dropout(convnet, 0.5)\n",
    "\n",
    "    convnet = fully_connected(convnet, 7, activation='softmax')\n",
    "    \n",
    "    return(convnet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/zt/.local/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/zt/.local/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "network = convn()\n",
    "network = regression(network, optimizer='adam', loss='categorical_crossentropy', learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/zt/Documents/Image_Classification/image-classifier-20\n"
     ]
    }
   ],
   "source": [
    "model = tflearn.DNN(network)\n",
    "model.load('image-classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 3)\n",
      "(32, 32, 3)\n",
      "Customer Area 4.79569e-16\n",
      "Gas_Station 0.0030171017\n",
      "Inventory 7.745581e-15\n",
      "Office_Space 9.273264e-09\n",
      "POS 7.6273086e-13\n",
      "Road_Signage 2.2513828e-10\n",
      "Shop_outdoor 0.9969829\n",
      "\n",
      "final prediction\n",
      " label =  Shop_outdoor \t  0.9969829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels=[\"Customer Area\",\"Gas_Station\",\"Inventory\",\"Office_Space\",\"POS\",\"Road_Signage\",\"Shop_outdoor\"]\n",
    "with tf.Session() as sess:\n",
    "    image = tf.read_file ('/home/zt/Documents/43338741.jpg')\n",
    "    image = tf.image.decode_jpeg(image, channels =3)\n",
    "    print(image.shape)\n",
    "    image.set_shape([None,None, 3])\n",
    "    image = tf.image.resize_images(image,(32,32))\n",
    "    print(image.shape)\n",
    "    image= image.eval(session=sess)\n",
    "\n",
    "    image = image/255\n",
    "\n",
    "prediction = model.predict([image])\n",
    "for i in range(len(labels)):\n",
    "    print(labels[i], prediction[0][i])\n",
    "\n",
    "result = np.argmax(prediction)\n",
    "\n",
    "print(\"\\nfinal prediction\\n\",\"label = \", labels[result],\"\\t \", prediction[0][result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
